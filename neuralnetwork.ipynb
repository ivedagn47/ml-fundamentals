{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267ea433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def act(k):\n",
    "    return 1 / (1 + np.exp(-k))\n",
    "\n",
    "def act_deri(k):\n",
    "    return k * (1 - k)\n",
    "\n",
    "class nn:\n",
    "    def __init__(self, inputs, learning_rate = 0.1):\n",
    "        self.lr = learning_rate\n",
    "        self.w1 = np.random.rand(inputs, 4)  # hidden layer with 4 neurons\n",
    "        self.b1 = np.random.rand(1, 4)\n",
    "        self.w2 = np.random.rand(4, 1)\n",
    "        self.b2 = np.random.rand(1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.z1 = np.dot(x, self.w1) + self.b1\n",
    "        self.a1 = act(self.z1)\n",
    "        self.z2 = np.dot(self.a1, self.w2) + self.b2\n",
    "        self.a2 = act(self.z2)\n",
    "        return self.a2\n",
    "    \n",
    "    def backward(self, x, y):\n",
    "        m = x.shape[0]\n",
    "        output = self.a2\n",
    "        error = output - y.reshape(-1, 1)\n",
    "        d_output = error * act_deri(output)  # (m, 1)\n",
    "\n",
    "        # Gradients for w2 and b2\n",
    "        d_w2 = np.dot(self.a1.T, d_output) / m  # (4, 1)\n",
    "        d_b2 = np.sum(d_output, axis=0, keepdims=True) / m  # (1, 1)\n",
    "\n",
    "        # Backpropagate to hidden layer\n",
    "        d_a1 = np.dot(d_output, self.w2.T)  # (m, 4)\n",
    "        d_z1 = d_a1 * act_deri(self.a1)     # (m, 4)\n",
    "\n",
    "        d_w1 = np.dot(x.T, d_z1) / m        # (inputs, 4)\n",
    "        d_b1 = np.sum(d_z1, axis=0, keepdims=True) / m  # (1, 4)\n",
    "\n",
    "        # Update weights and biases\n",
    "        self.w2 -= self.lr * d_w2\n",
    "        self.b2 -= self.lr * d_b2\n",
    "        self.w1 -= self.lr * d_w1\n",
    "        self.b1 -= self.lr * d_b1\n",
    "\n",
    "    def train(self, x, y, epochs=1000):\n",
    "        for i in range(epochs):\n",
    "            self.forward(x)\n",
    "            self.backward(x, y)\n",
    "            if i % 100 == 0:\n",
    "                loss = np.mean((self.a2 - y.reshape(-1, 1)) ** 2)\n",
    "                print(f\"Epoch {i}, Loss: {loss}\")\n",
    "\n",
    "\n",
    "# x = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "# y = np.array([0,1,1,0])\n",
    "# net = nn(inputs=2, learning_rate=0.1)\n",
    "# net.train(x, y, epochs=1000)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
